{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hEe13CZ8t_YG"
      },
      "source": [
        "Dataset Loading"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "1J0IuNOJwuy3",
        "outputId": "bb680bf0-ff78-401f-99b8-0f55353d8c87"
      },
      "outputs": [],
      "source": [
        "# Uploading file from local disk to colab drive\n",
        "# from google.colab import files\n",
        "# files.upload()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "yHMBJgXyuAie"
      },
      "outputs": [],
      "source": [
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "bwc2tz_ruJ9b"
      },
      "outputs": [],
      "source": [
        "data = pd.read_csv(\n",
        "    \"SMSSpamCollection\",\n",
        "    sep=\"\\t\", ##Split each row into columns wherever there is a TAB\n",
        "    header=None, ##There is no header row in the file.\n",
        "    names=[\"label\", \"message\"] ##there is no header, we manually assign column names: labels --> spam or ham ; massege --> actual SMS text\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BlIXxxrEv0ho"
      },
      "source": [
        "Converting labels to binary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "x2NjFhMhvzo5"
      },
      "outputs": [],
      "source": [
        "data[\"label\"] = data[\"label\"].map({\"ham\": 0, \"spam\": 1})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6PZnknPlv5hM",
        "outputId": "d640d78b-069e-4126-d9b8-36b67e2d0164"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   label                                            message\n",
            "0      0  Go until jurong point, crazy.. Available only ...\n",
            "1      0                      Ok lar... Joking wif u oni...\n",
            "2      1  Free entry in 2 a wkly comp to win FA Cup fina...\n",
            "3      0  U dun say so early hor... U c already then say...\n",
            "4      0  Nah I don't think he goes to usf, he lives aro...\n"
          ]
        }
      ],
      "source": [
        "print(data.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nc1aiQs-xsqN"
      },
      "source": [
        "##Text Processing\n",
        "Preprocess the text data( like lower case, lemmatization, stop word removal, remove non\n",
        "alphabetic tokens etc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nZPsZds-xfI9",
        "outputId": "f18b68c1-9ec7-4a9f-d801-b8bc4fe88313"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0    go jurong point crazy available bugis n great ...\n",
            "1                              ok lar joking wif u oni\n",
            "2    free entry wkly comp win fa cup final tkts st ...\n",
            "3                  u dun say early hor u c already say\n",
            "4             nah dont think go usf life around though\n",
            "Name: text_clean, dtype: object\n"
          ]
        }
      ],
      "source": [
        "import re     #Handles regular expressions for pattern-based text cleaning\n",
        "import nltk   #Core Natural Language Toolkit for NLP tasks.\n",
        "from nltk.corpus import stopwords #Provides common English stop words (\"the\", \"is\", \"and\") that carry little meaning\n",
        "from nltk.stem import WordNetLemmatizer  #Reduces words to their base/dictionary form (e.g., \"running\" → \"run\")\n",
        "nltk.download('stopwords', quiet=True)\n",
        "nltk.download('wordnet', quiet=True)\n",
        "nltk.download('omw-1.4', quiet=True)\n",
        "stop_words = set(stopwords.words('english')) #creates a set of ~179 common English words (\"the\", \"is\", \"and\", \"to\", etc.)\n",
        "lemmatizer = WordNetLemmatizer() #initializes NLTK's lemmatizer\n",
        "\n",
        "def preprocess(text):\n",
        "    text = text.lower() #Converts all characters to lowercase\n",
        "    text = re.sub(r'[^a-zA-Z\\s]', '', text)  # Remove non-alphabetic\n",
        "    words = text.split()\n",
        "    words = [lemmatizer.lemmatize(word) for word in words if word not in stop_words]\n",
        "    return ' '.join(words) #Rejoins filtered lemmas with spaces, producing string output for TF-IDF.\n",
        "data['text_clean'] = data['message'].apply(preprocess)\n",
        "print(data['text_clean'].head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "USNNJqEc3oiQ"
      },
      "source": [
        "Preprocess the text dataset by converting words into numerical features using TF-IDF"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_wDlqN2N21-K",
        "outputId": "44703ebc-381e-40eb-9845-73dac3d18e23"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "TF-IDF shape: (5572, 1529)\n"
          ]
        }
      ],
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "# Transforms text into TF-IDF matrix where each word's importance = Term Frequency × Inverse Document Frequency.\n",
        "vectorizer = TfidfVectorizer(max_features=3000, min_df=5)  #'max_features\": Limits vocabulary to top 3000 most frequent terms (reduces dimensionality from ~10k+ to manageable size).\n",
        "X = vectorizer.fit_transform(data['text_clean'])  # \"min_df\" : gnores words appearing in <5 documents (filters rare noise terms).\n",
        "y = data['label']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "print(\"TF-IDF shape:\", X.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LrRj7zGO548N"
      },
      "source": [
        "###Perceptron Training and Evaluation\n",
        "Train Perceptron, compute accuracy/precision/recall for non-spam (ham, class 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UlNs-wy85oaE",
        "outputId": "aca155cf-2f6b-4346-c377-ea9e724a8bf4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 0.966\n",
            "Ham Precision: 0.983, Recall: 0.977\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         ham       0.98      0.98      0.98       966\n",
            "        spam       0.86      0.89      0.88       149\n",
            "\n",
            "    accuracy                           0.97      1115\n",
            "   macro avg       0.92      0.93      0.93      1115\n",
            "weighted avg       0.97      0.97      0.97      1115\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.linear_model import Perceptron\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, classification_report\n",
        "\n",
        "model = Perceptron(max_iter=1000, random_state=42)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "acc = accuracy_score(y_test, y_pred)\n",
        "prec_ham = precision_score(y_test, y_pred, pos_label=0)  # Non-spam precision\n",
        "rec_ham = recall_score(y_test, y_pred, pos_label=0)     # Non-spam recall\n",
        "\n",
        "print(f\"Accuracy: {acc:.3f}\")\n",
        "print(f\"Ham Precision: {prec_ham:.3f}, Recall: {rec_ham:.3f}\")\n",
        "print(classification_report(y_test, y_pred, target_names=['ham', 'spam']))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L_MT4cVQ6hbZ"
      },
      "source": [
        "###Limitations\n",
        "Perceptron assumes linear separability, struggling with non-linear SMS patterns (e.g., sarcasm) or class imbalance without tweaks. It lacks probabilistic outputs and may overfit sparse TF-IDF features; better for binary tasks but inferior to Logistic Regression/SVM (~96% acc) on this dataset."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
